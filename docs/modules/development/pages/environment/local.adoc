= Local Minikube Environment
:tekton-pipelines-version: 0.22.0
:tekton-triggers-version: 0.12.1
:knative-eventing-version: 0.21.3

This document describes the suggested local development setup.

== System requirements

To be able to run Agogos and Please make sure you have following requirements installed:

// * link:https://sdkman.io/jdks#jdk.java.net[JDK 11]
* CLI tools
** link:https://kubernetes.io/docs/tasks/tools/install-kubectl/[kubectl]
** link:https://tekton.dev/docs/cli/[tkn]
* xref:environment/local.adoc#minikube[Minikube]
* xref:environment/local.adoc#tekton-pipelines[Tekton Pipelines]
* xref:environment/local.adoc#tekton-triggers[Tekton Triggers]
* xref:environment/local.adoc#knative-eventing[Knative Eventing]

[#minikube]
=== Minikube

Recommended version:: Latest
Documentation:: link:https://minikube.sigs.k8s.io/docs/start/[Official installation guide].

You may want to assign more resources to your installation. In case you use `kvm2`
driver you could use this command:

[source,bash]
----
‚ùØ minikube start --driver=kvm2 --cpus=4 --memory=6g --disk-size=30GB
----

[#tekton-pipelines]
=== Tekton Pipelines

Recommended version:: `{tekton-pipelines-version}`
Documentation:: See official documentation for link:https://tekton.dev/docs/getting-started/#installation[Tekton Pipelines] installation.

For your convenience we are providing required commands below (version `{tekton-pipelines-version}`).

[source,bash,subs="attributes+"]
----
‚ùØ kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/previous/v{tekton-pipelines-version}/release.yaml
----

[#tekton-triggers]
=== Tekton Triggers

Recommended version:: `{tekton-triggers-version}`
Documentation:: See official documentation for link:https://tekton.dev/docs/triggers/install/[Tekton Triggers] installation.

For your convenience we are providing required commands below (version `{tekton-triggers-version}`).

[source,bash,subs="attributes+"]
----
‚ùØ kubectl apply -f https://storage.googleapis.com/tekton-releases/triggers/previous/v{tekton-triggers-version}/release.yaml
----

[#knative-eventing]
=== Knative Eventing

Recommended version:: `{knative-eventing-version}`
Documentation:: Official documentation on link:https://knative.dev/docs/install/any-kubernetes-cluster/#installing-the-eventing-component[how to install Knative Eventing].

For your convenience we are providing required commands below (version `{knative-eventing-version}`).

. Install the Custom Resource Definitions.
+
[source,bash,subs="attributes+"]
----
‚ùØ kubectl apply --filename https://github.com/knative/eventing/releases/download/v{knative-eventing-version}/eventing-crds.yaml
----
+
. Install Eventing core components.
+
[source,bash,subs="attributes+"]
----
‚ùØ kubectl apply --filename https://github.com/knative/eventing/releases/download/v{knative-eventing-version}/eventing-core.yaml
----
+
. Install a In-Memory (standalone) default Channel.
+
[source,bash,subs="attributes+"]
----
‚ùØ kubectl apply --filename https://github.com/knative/eventing/releases/download/v{knative-eventing-version}/in-memory-channel.yaml
----
+
. Install a MT-Channel-based Broker.
+
[source,bash,subs="attributes+"]
----
‚ùØ kubectl apply --filename https://github.com/knative/eventing/releases/download/v{knative-eventing-version}/mt-channel-broker.yaml
----

You can monitor the status of Knative Eventing pods using this command:

[source,bash]
----
‚ùØ kubectl get pods -n knative-eventing
----

== Gotchas

[#managing-contexts]
=== Managing contexts

Kubernetes contexts are managed globally. This means that any time you will have
one active context.

[NOTE]
====
Kubernetes documentation references:

* link:https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/[Organizing Cluster Access Using kubeconfig Files]
* link:https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/[Configure Access to Multiple Clusters]
====

After starting Minikube, the current context is switched to `minikube`. This means
that any commands executed using `kubectl` or `oc` will be run against your local
Minikube cluster.

There are many ways how multiple contexts can be managed, two of them:

1. Manage contexts with `kubectl config` commands
+
To switch to a different use the `kubectl config use-context` command.
To list all available contexts run `kubectl config get-contexts`.
2. Use separate kubeconfig files for different use cases
+
You can maintain the minikube context in a separate kubeconfig file.
This will make it possible to switch to Minikube context by setting an environment variable.
Run the below command to create (or update) your minikube context in specified file.
+
[source,bash]
----
‚ùØ export KUBECONFIG=~/.kube/minikube.yaml
‚ùØ minikube update-context
üéâ  "minikube" context has been updated to point to 192.168.39.112:8443
üíó  Current context is "minikube"
----
+
To use the Minikube context you will need to run `export KUBECONFIG=~/.kube/minikube.yaml`
in the terminal before interacting with the cluster.

== Known issues

This section describes known issues and limitations with the setup.

=== Minikube failing to start due to `PROVIDER_KVM2_ERROR`

If you see error similar to what can be found below, just start Minikube again. It will work.

[source,bash]
----
‚ùØ minikube start
üòÑ  minikube v1.17.1 on Fedora 33
‚ú®  Using the kvm2 driver based on existing profile

üí£  Exiting due to PROVIDER_KVM2_ERROR: /usr/bin/virsh domcapabilities --virttype kvm failed:

üí°  Suggestion: Follow your Linux distribution instructions for configuring KVM
üìò  Documentation: https://minikube.sigs.k8s.io/docs/reference/drivers/kvm2
----
